{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normal Neural Network: MNIST example\n",
    "\n",
    "In this example, we train a simple network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import seaborn\n",
    "seaborn.set(font_scale=2)\n",
    "seaborn.set_style(\"white\")\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import numpy as np\n",
    "from scipy.spatial import HalfspaceIntersection\n",
    "import warnings\n",
    "\n",
    "pritn = print\n",
    "\n",
    "from convex_adversarial import robust_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/tako/anaconda3/envs/lsy/bin/python\n"
     ]
    }
   ],
   "source": [
    "## 어떤 python에서 돌아가는지\n",
    "## 환경, 버전\n",
    "print(sys.executable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['', '/home/tako/anaconda3/envs/lsy/lib/python36.zip', '/home/tako/anaconda3/envs/lsy/lib/python3.6', '/home/tako/anaconda3/envs/lsy/lib/python3.6/lib-dynload', '/home/tako/anaconda3/envs/lsy/lib/python3.6/site-packages', '/home/tako/anaconda3/envs/lsy/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg', '/home/tako/anaconda3/envs/lsy/lib/python3.6/site-packages/IPython/extensions', '/home/tako/.ipython', '../']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## warning 없애기\n",
    "if not sys.warnoptions:\n",
    "    warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "<torch.cuda.device object at 0x7fe94daa41d0>\n",
      "2\n",
      "TITAN Xp\n"
     ]
    }
   ],
   "source": [
    "### GPU 연결 확인\n",
    "print(torch.cuda.current_device()) #연결된 gpu idx\n",
    "print(torch.cuda.device(0))\n",
    "print(torch.cuda.device_count()) #연결된 gpu갯수\n",
    "print(torch.cuda.get_device_name(0)) #연결된 gpu이름"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_trainset = datasets.MNIST(root='./data/', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_testset = datasets.MNIST(root='./data/', train=False, download=True, transform=transforms.ToTensor())\n",
    "data_loader  = torch.utils.data.DataLoader(dataset=mnist_trainset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)\n",
    "test_data_loader  = torch.utils.data.DataLoader(dataset=mnist_testset,\n",
    "                                          batch_size=50,\n",
    "                                          shuffle=True,\n",
    "                                          num_workers=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = mnist_trainset.train_data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000, 28, 28]), torch.Size([10000, 28, 28]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset.train_data.shape, mnist_testset.test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([60000]), torch.Size([10000]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist_trainset.train_labels.shape, mnist_testset.test_labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max and min 255 0\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_ex = mnist_trainset.train_data[0].numpy()\n",
    "print('max and min', train_ex.max(), train_ex.min())\n",
    "plt.imshow(train_ex, 'gray')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = mnist_trainset.train_data\n",
    "y_train = mnist_trainset.train_labels\n",
    "X_test = mnist_testset.test_data\n",
    "y_test = mnist_testset.test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x.view(x.size()[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normal Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 0.1 #0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------------------------\n",
      "<<<<< 0 th iteration >>>>>\n",
      "Plain err: 0.94000\n",
      "Plain err: 0.06000\n",
      "------------------------------------------------------------\n",
      "<<<<< 1 th iteration >>>>>\n",
      "Plain err: 0.04000\n",
      "Plain err: 0.06000\n",
      "------------------------------------------------------------\n",
      "<<<<< 2 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 3 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 4 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 5 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.06000\n",
      "------------------------------------------------------------\n",
      "<<<<< 6 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 7 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 8 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 9 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 10 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 11 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 12 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 13 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 14 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 15 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 16 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 17 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 18 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 19 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 20 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 21 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 22 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 23 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 24 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 25 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 26 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 27 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 28 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 29 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 30 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 31 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 32 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 33 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 34 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 35 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 36 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 37 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 38 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 39 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 40 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 41 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 42 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 43 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 44 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 45 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 46 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 47 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 48 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 49 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 50 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 51 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 52 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 53 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 54 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 55 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 56 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.02000\n",
      "------------------------------------------------------------\n",
      "<<<<< 57 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 58 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 59 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 60 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 61 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 62 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 63 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 64 th iteration >>>>>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 65 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 66 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 67 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 68 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 69 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 70 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 71 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 72 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 73 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 74 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 75 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 76 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 77 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 78 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 79 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 80 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 81 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 82 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 83 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 84 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 85 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 86 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 87 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 88 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 89 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 90 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 91 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 92 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 93 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 94 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 95 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 96 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 97 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 98 th iteration >>>>>\n",
      "Plain err: 0.02000\n",
      "Plain err: 0.00000\n",
      "------------------------------------------------------------\n",
      "<<<<< 99 th iteration >>>>>\n",
      "Plain err: 0.00000\n",
      "Plain err: 0.00000\n",
      "last loss: 0.000028\n",
      "737.0307269096375\n"
     ]
    }
   ],
   "source": [
    "#torch.manual_seed(1)\n",
    "net = nn.Sequential(\n",
    "    nn.Conv2d(1,16, 2, stride=(2,2)),\n",
    "    nn.ReLU(),\n",
    "    nn.Conv2d(16,32, 2, stride=(2,2)),\n",
    "    nn.ReLU(),\n",
    "    Flatten(),\n",
    "    nn.Linear(7*7*32,100),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(100,10)\n",
    ")\n",
    "\n",
    "st = time.time()\n",
    "opt = optim.Adam(net.parameters(), lr=1e-3)\n",
    "# for i in range(1000):\n",
    "#     out = net(Variable(X_train))\n",
    "#     l = nn.CrossEntropyLoss()(out, Variable(y_train))\n",
    "#     err = (out.max(1)[1].data != y_train).float().mean()\n",
    "#     if i % 100 == 0:\n",
    "#         print('loss: %.6f, err: %.3f'%(l.data[0], err))\n",
    "#     opt.zero_grad()\n",
    "#     (l).backward()\n",
    "#     opt.step()\n",
    "for i in range(100):\n",
    "    print('-'*60)\n",
    "    print('<'*5, i,'th iteration', '>'*5)\n",
    "    for j, (batch_images, batch_labels) in enumerate(data_loader):\n",
    "        X = Variable(batch_images.cuda())\n",
    "        Y = Variable(batch_labels.cuda())        \n",
    "            \n",
    "        out = net.cuda()(X)\n",
    "        l2 = nn.CrossEntropyLoss()(out, Y)\n",
    "        err = (out.max(1)[1].data != batch_labels.cuda()).float().mean()\n",
    "        \n",
    "        if j % (n_samples//(2*batch_size)) == 0:\n",
    "            print('Plain err: %.5f'%(err))\n",
    "        opt.zero_grad()\n",
    "        l2.backward()\n",
    "        opt.step()\n",
    "        if j % 10 == 0:\n",
    "             print('%.2f %%'%(100*j/(n_samples/(batch_size))), end='\\r')\n",
    "    \n",
    "print('last loss: %.6f'%l2)\n",
    "print(time.time()-st)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python (lsy)",
   "language": "python",
   "name": "lsy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
